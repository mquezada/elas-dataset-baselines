{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# utility function for creating input files for fasttext\n",
    "\n",
    "import string\n",
    "\n",
    "def FTInputFile(categoriesFile,xFile,yFile,labelString,outFile):\n",
    "    category = []\n",
    "    i = 0\n",
    "    with open(categoriesFile) as f:\n",
    "        for line in f:\n",
    "            category.append(str(i))\n",
    "            i = i+1\n",
    "\n",
    "    with open(xFile) as xf, open(yFile) as yf, open(outFile,'w') as out:\n",
    "        for x,y in zip(xf,yf):\n",
    "            strX = \"\".join([c for c in x[:-1] if c not in string.punctuation]).lower()\n",
    "            out.write(labelString + category[int(y)] + \" \" + strX)\n",
    "            out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general vars\n",
    "\n",
    "_dataDir = \"../../data/\"\n",
    "\n",
    "ftlabel = \"__label__\"\n",
    "wVectors = \"../../word_vectors/wiki.es.vec\"\n",
    "dimensions = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create input files for fasttext\n",
    "\n",
    "_tmpTrainFile = \"_train_\"\n",
    "_tmpDevFile = \"_dev_\"\n",
    "_tmpTestFile = \"_test_\"\n",
    "\n",
    "for tt in [\"_train_\", \"_dev_\", \"_test_\"]:\n",
    "    for i in [1,2,3,4]:\n",
    "        tema = str(i)\n",
    "        FTInputFile(_dataDir + \"categorias_tema_\" + tema + \"_pnud_0.txt\",\n",
    "                    _dataDir + \"x\" + tt + \"tema_\" + tema + \"_categorias_pnud_0.txt\",\n",
    "                    _dataDir + \"y\" + tt + \"tema_\" + tema + \"_categorias_pnud_0.txt\",\n",
    "                    ftlabel,\n",
    "                    tt + tema + \".tmp\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#********************\n",
    "#*** FINISH tema 1: \n",
    "#*** best recall at 1: 0.6731728475384949 with parameters (0.06, 5, 5)\n",
    "#*** model stored at _model_ptvec_1_best_at_1.bin\n",
    "#*** best recall at 5: 0.9071784862285838 with dimensions (0.05, 5, 5)\n",
    "#*** model stored at _model_ptvec_1_best_at_5.bin\n",
    "#********************\n",
    "\n",
    "\n",
    "# train N models for every \"tema\" and keep the best models on the dev set according to recall @1 and @5\n",
    "# usign pretrained vectors wiki.es.vec\n",
    "\n",
    "import itertools\n",
    "\n",
    "# number of repetitions\n",
    "N = 5\n",
    "\n",
    "# temas\n",
    "temas = [1,2,3,4]\n",
    "\n",
    "# prefix for the generated model\n",
    "model_name = \"_model_ptvec_\"\n",
    "\n",
    "# parameters\n",
    "dim = 300\n",
    "lrs = [0.05, 0.06, 0.065]\n",
    "window_sizes = [5]\n",
    "epochs = [5,10]\n",
    "#neg_samples = [5,6,7]\n",
    "#word_ngrams = [1,2,3]\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "# create a model for each \"tema\"\n",
    "for t in temas:\n",
    "    tema = str(t)\n",
    "    \n",
    "    best_classifier_at_1 = None\n",
    "    best_parameters_at_1 = None\n",
    "    best_classifier_at_5 = None\n",
    "    best_parameters_at_5 = None \n",
    "    \n",
    "    best_recall_at_1 = 0\n",
    "    best_recall_at_5 = 0\n",
    "    \n",
    "\n",
    "    # best models in previous experiments\n",
    "    if t == 1:\n",
    "        best_recall_at_1 = 0.65\n",
    "        best_recall_at_5 = 0.89   \n",
    "        \n",
    "    if t == 2:\n",
    "        best_recall_at_1 = 0.71\n",
    "        best_recall_at_5 = 0.91\n",
    "    \n",
    "    if t == 3:\n",
    "        best_recall_at_1 = 0.71\n",
    "        best_recall_at_5 = 0.91   \n",
    "        \n",
    "    if t == 4:\n",
    "        best_recall_at_1 = 0.70\n",
    "        best_recall_at_5 = 0.91\n",
    "\n",
    "\n",
    "    print(\"*** BEGIN tema \" + tema + \": \")\n",
    "    \n",
    "    # Perfomr a grid search for all combinations of parameters. \n",
    "    # For every combination do N repetitions\n",
    "    \n",
    "    dim_ant = 0\n",
    "    for (lr,ws,e) in itertools.product(lrs,window_sizes,epochs):\n",
    "        for i in range(0,N):\n",
    "            if i == 0:\n",
    "                print(\"Checking the combination \" + str((lr,ws,e)))\n",
    "            sys.stdout.write(str(i) + \" \")\n",
    "            classifier = fasttext.supervised(\"_train_\" + tema + \".tmp\",\n",
    "                                             model_name + tema,\n",
    "                                             label_prefix = ftlabel,\n",
    "                                             dim = dim,\n",
    "                                             lr = lr,\n",
    "                                             ws = ws,\n",
    "                                             epoch = e,\n",
    "                                             pretrained_vectors = wVectors\n",
    "                                            )\n",
    "            \n",
    "            result_at_1 = classifier.test(\"_dev_\" + tema + \".tmp\", k=1)\n",
    "            result_at_5 = classifier.test(\"_dev_\" + tema + \".tmp\", k=5)\n",
    "\n",
    "            if result_at_1.recall > best_recall_at_1:\n",
    "                best_recall_at_1 = result_at_1.recall\n",
    "                best_classifier_at_1 = classifier\n",
    "                best_parameters_at_1 = (lr,ws,e)\n",
    "                shutil.copyfile(model_name + tema + \".bin\", model_name + tema + \"_best_at_1.bin\")\n",
    "                print(\"* updating best recall at 1 with parameters \" + str(best_parameters_at_1) + \" best recall at 1 so far: \" + str(best_recall_at_1))\n",
    "\n",
    "            if result_at_5.recall > best_recall_at_5:\n",
    "                best_recall_at_5 = result_at_5.recall \n",
    "                best_classifier_at_5 = classifier\n",
    "                best_parameters_at_5 = (lr,ws,e)\n",
    "                shutil.copyfile(model_name + tema + \".bin\", model_name + tema + \"_best_at_5.bin\")\n",
    "                print(\"* updating best recall at 5 with parameters \" + str(best_parameters_at_5) + \" best recall at 5 so far: \" + str(best_recall_at_5))\n",
    "\n",
    "            os.remove(model_name + tema + \".bin\")\n",
    "            if i == N-1:\n",
    "                print(\" (done)\")\n",
    "\n",
    "    print(\"********************\")\n",
    "    print(\"*** FINISH tema \" + tema + \": \")\n",
    "    print(\"*** best recall at 1: \" + str(best_recall_at_1) + \" with parameters \" + str(best_parameters_at_1))\n",
    "    print(\"*** model stored at \" + model_name + tema + \"_best_at_1.bin\")\n",
    "    print(\"*** best recall at 5: \" + str(best_recall_at_5) + \" with dimensions \" + str(best_parameters_at_5))\n",
    "    print(\"*** model stored at \" + model_name + tema + \"_best_at_5.bin\")\n",
    "    print(\"********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#********************\n",
    "#*** FINISH tema 2: \n",
    "#*** best recall at 1: 0.7224891329215283 with parameters (0.05, 5, 10)\n",
    "#*** model stored at _model_ptvec_2_best_at_1.bin\n",
    "#*** best recall at 5: 0.9256463051933196 with dimensions (0.065, 5, 5)\n",
    "#*** model stored at _model_ptvec_2_best_at_5.bin\n",
    "#********************\n",
    "\n",
    "#********************\n",
    "#*** FINISH tema 3: \n",
    "#*** best recall at 1: 0.7637677547969101 with parameters (0.05, 5, 5)\n",
    "#*** model stored at _model_ptvec_3_best_at_1.bin\n",
    "#*** best recall at 5: 0.9641166209818092 with dimensions (0.05, 5, 5)\n",
    "#*** model stored at _model_ptvec_3_best_at_5.bin\n",
    "#********************\n",
    "\n",
    "#********************\n",
    "#*** FINISH tema 4: \n",
    "#*** best recall at 1: 0.7086513994910941 with parameters (0.05, 5, 5)\n",
    "#*** model stored at _model_ptvec_4_best_at_1.bin\n",
    "#*** best recall at 5: 0.9223918575063613 with dimensions (0.05, 5, 5)\n",
    "#*** model stored at _model_ptvec_4_best_at_5.bin\n",
    "#********************\n",
    "\n",
    "\n",
    "# train N models for every \"tema\" and keep the best models on the dev set according to recall @1 and @5\n",
    "# usign pretrained vectors wiki.es.vec\n",
    "\n",
    "import itertools\n",
    "\n",
    "# number of repetitions\n",
    "N = 5\n",
    "\n",
    "# temas\n",
    "temas = [2,3,4]\n",
    "\n",
    "# prefix for the generated model\n",
    "model_name = \"_model_ptvec_\"\n",
    "\n",
    "# parameters\n",
    "dim = 300\n",
    "lrs = [0.05, 0.06, 0.065]\n",
    "window_sizes = [5]\n",
    "epochs = [5,10]\n",
    "#neg_samples = [5,6,7]\n",
    "#word_ngrams = [1,2,3]\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "# create a model for each \"tema\"\n",
    "for t in temas:\n",
    "    tema = str(t)\n",
    "    \n",
    "    best_classifier_at_1 = None\n",
    "    best_parameters_at_1 = None\n",
    "    best_classifier_at_5 = None\n",
    "    best_parameters_at_5 = None \n",
    "    \n",
    "    best_recall_at_1 = 0\n",
    "    best_recall_at_5 = 0\n",
    "    \n",
    "\n",
    "    # best models in previous experiments\n",
    "    if t == 1:\n",
    "        best_recall_at_1 = 0.65\n",
    "        best_recall_at_5 = 0.89   \n",
    "        \n",
    "    if t == 2:\n",
    "        best_recall_at_1 = 0.71\n",
    "        best_recall_at_5 = 0.91\n",
    "    \n",
    "    if t == 3:\n",
    "        best_recall_at_1 = 0.71\n",
    "        best_recall_at_5 = 0.91   \n",
    "        \n",
    "    if t == 4:\n",
    "        best_recall_at_1 = 0.70\n",
    "        best_recall_at_5 = 0.91\n",
    "\n",
    "\n",
    "    print(\"*** BEGIN tema \" + tema + \": \")\n",
    "    \n",
    "    # Perfomr a grid search for all combinations of parameters. \n",
    "    # For every combination do N repetitions\n",
    "    \n",
    "    dim_ant = 0\n",
    "    for (lr,ws,e) in itertools.product(lrs,window_sizes,epochs):\n",
    "        for i in range(0,N):\n",
    "            if i == 0:\n",
    "                print(\"Checking the combination \" + str((lr,ws,e)))\n",
    "            sys.stdout.write(str(i) + \" \")\n",
    "            classifier = fasttext.supervised(\"_train_\" + tema + \".tmp\",\n",
    "                                             model_name + tema,\n",
    "                                             label_prefix = ftlabel,\n",
    "                                             dim = dim,\n",
    "                                             lr = lr,\n",
    "                                             ws = ws,\n",
    "                                             epoch = e,\n",
    "                                             pretrained_vectors = wVectors\n",
    "                                            )\n",
    "            \n",
    "            result_at_1 = classifier.test(\"_dev_\" + tema + \".tmp\", k=1)\n",
    "            result_at_5 = classifier.test(\"_dev_\" + tema + \".tmp\", k=5)\n",
    "\n",
    "            if result_at_1.recall > best_recall_at_1:\n",
    "                best_recall_at_1 = result_at_1.recall\n",
    "                best_classifier_at_1 = classifier\n",
    "                best_parameters_at_1 = (lr,ws,e)\n",
    "                shutil.copyfile(model_name + tema + \".bin\", model_name + tema + \"_best_at_1.bin\")\n",
    "                print(\"* updating best recall at 1 with parameters \" + str(best_parameters_at_1) + \" best recall at 1 so far: \" + str(best_recall_at_1))\n",
    "\n",
    "            if result_at_5.recall > best_recall_at_5:\n",
    "                best_recall_at_5 = result_at_5.recall \n",
    "                best_classifier_at_5 = classifier\n",
    "                best_parameters_at_5 = (lr,ws,e)\n",
    "                shutil.copyfile(model_name + tema + \".bin\", model_name + tema + \"_best_at_5.bin\")\n",
    "                print(\"* updating best recall at 5 with parameters \" + str(best_parameters_at_5) + \" best recall at 5 so far: \" + str(best_recall_at_5))\n",
    "\n",
    "            os.remove(model_name + tema + \".bin\")\n",
    "            if i == N-1:\n",
    "                print(\" (done)\")\n",
    "\n",
    "    print(\"********************\")\n",
    "    print(\"*** FINISH tema \" + tema + \": \")\n",
    "    print(\"*** best recall at 1: \" + str(best_recall_at_1) + \" with parameters \" + str(best_parameters_at_1))\n",
    "    print(\"*** model stored at \" + model_name + tema + \"_best_at_1.bin\")\n",
    "    print(\"*** best recall at 5: \" + str(best_recall_at_5) + \" with dimensions \" + str(best_parameters_at_5))\n",
    "    print(\"*** model stored at \" + model_name + tema + \"_best_at_5.bin\")\n",
    "    print(\"********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BIGRAMS\n",
    "# train N models for every \"tema\" and keep the best models on the dev set according to recall @1 and @5\n",
    "# usign pretrained vectors wiki.es.vec\n",
    "\n",
    "#********************\n",
    "#*** FINISH tema 1: \n",
    "#*** best recall at 1: 0.6829321188462373 with parameters (0.08, 5, 5)\n",
    "#*** model stored at _model_ptvec_ng2_1_best_at_1.bin\n",
    "#*** best recall at 5: 0.9024072869225764 with dimensions (0.08, 5, 5)\n",
    "#*** model stored at _model_ptvec_ng2_1_best_at_5.bin\n",
    "#********************\n",
    "\n",
    "#********************\n",
    "#*** FINISH tema 2: \n",
    "#*** best recall at 1: 0.7236330359185541 with parameters (0.05, 5, 10)\n",
    "#*** model stored at _model_ptvec_ng2_2_best_at_1.bin\n",
    "#*** best recall at 5: 0.9233584991992679 with dimensions (0.08, 5, 5)\n",
    "#*** model stored at _model_ptvec_ng2_2_best_at_5.bin\n",
    "#********************\n",
    "\n",
    "# STOPPED AFTER TEMA 2\n",
    "\n",
    "import itertools\n",
    "\n",
    "# number of repetitions\n",
    "N = 5\n",
    "\n",
    "# temas\n",
    "temas = [1,2]\n",
    "\n",
    "word_ngrams = 2\n",
    "# prefix for the generated model\n",
    "model_name = \"_model_ptvec_ng\" + str(word_ngrams) + \"_\"\n",
    "\n",
    "# parameters\n",
    "dim = 300\n",
    "lrs = [0.05, 0.08, 0.1]\n",
    "window_sizes = [5]\n",
    "epochs = [5,10]\n",
    "#neg_samples = [5,6,7]\n",
    "#word_ngrams = [1,2,3]\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "# create a model for each \"tema\"\n",
    "for t in temas:\n",
    "    tema = str(t)\n",
    "    \n",
    "    best_classifier_at_1 = None\n",
    "    best_parameters_at_1 = None\n",
    "    best_classifier_at_5 = None\n",
    "    best_parameters_at_5 = None \n",
    "    \n",
    "    best_recall_at_1 = 0\n",
    "    best_recall_at_5 = 0\n",
    "\n",
    "    print(\"*** BEGIN tema \" + tema + \": \")\n",
    "    \n",
    "    # Perfomr a grid search for all combinations of parameters. \n",
    "    # For every combination do N repetitions\n",
    "    \n",
    "    dim_ant = 0\n",
    "    for (lr,ws,e) in itertools.product(lrs,window_sizes,epochs):\n",
    "        for i in range(0,N):\n",
    "            if i == 0:\n",
    "                print(\"Checking the combination \" + str((lr,ws,e)))\n",
    "            sys.stdout.write(str(i) + \" \")\n",
    "            classifier = fasttext.supervised(\"_train_\" + tema + \".tmp\",\n",
    "                                             model_name + tema,\n",
    "                                             label_prefix = ftlabel,\n",
    "                                             dim = dim,\n",
    "                                             lr = lr,\n",
    "                                             ws = ws,\n",
    "                                             epoch = e,\n",
    "                                             pretrained_vectors = wVectors,\n",
    "                                             word_ngrams = word_ngrams,\n",
    "                                             bucket = 2000000\n",
    "                                            )\n",
    "            \n",
    "            result_at_1 = classifier.test(\"_dev_\" + tema + \".tmp\", k=1)\n",
    "            result_at_5 = classifier.test(\"_dev_\" + tema + \".tmp\", k=5)\n",
    "\n",
    "            if result_at_1.recall > best_recall_at_1:\n",
    "                best_recall_at_1 = result_at_1.recall\n",
    "                best_classifier_at_1 = classifier\n",
    "                best_parameters_at_1 = (lr,ws,e)\n",
    "                shutil.copyfile(model_name + tema + \".bin\", model_name + tema + \"_best_at_1.bin\")\n",
    "                print(\"* updating best recall at 1 with parameters \" + str(best_parameters_at_1) + \" best recall at 1 so far: \" + str(best_recall_at_1))\n",
    "\n",
    "            if result_at_5.recall > best_recall_at_5:\n",
    "                best_recall_at_5 = result_at_5.recall \n",
    "                best_classifier_at_5 = classifier\n",
    "                best_parameters_at_5 = (lr,ws,e)\n",
    "                shutil.copyfile(model_name + tema + \".bin\", model_name + tema + \"_best_at_5.bin\")\n",
    "                print(\"* updating best recall at 5 with parameters \" + str(best_parameters_at_5) + \" best recall at 5 so far: \" + str(best_recall_at_5))\n",
    "\n",
    "            os.remove(model_name + tema + \".bin\")\n",
    "            if i == N-1:\n",
    "                print(\" (done)\")\n",
    "\n",
    "    print(\"********************\")\n",
    "    print(\"*** FINISH tema \" + tema + \": \")\n",
    "    print(\"*** best recall at 1: \" + str(best_recall_at_1) + \" with parameters \" + str(best_parameters_at_1))\n",
    "    print(\"*** model stored at \" + model_name + tema + \"_best_at_1.bin\")\n",
    "    print(\"*** best recall at 5: \" + str(best_recall_at_5) + \" with dimensions \" + str(best_parameters_at_5))\n",
    "    print(\"*** model stored at \" + model_name + tema + \"_best_at_5.bin\")\n",
    "    print(\"********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BIGRAMS\n",
    "# train N models for every \"tema\" and keep the best models on the dev set according to recall @1 and @5\n",
    "# usign pretrained vectors wiki.es.vec\n",
    "\n",
    "#********************\n",
    "#*** FINISH tema 3: \n",
    "#*** best recall at 1: 0.7754796910042362 with parameters (0.05, 5, 5)\n",
    "#*** model stored at _model_ptvec_ng2_3_best_at_1.bin\n",
    "#*** best recall at 5: 0.9613755295290306 with dimensions (0.05, 5, 5)\n",
    "#*** model stored at _model_ptvec_ng2_3_best_at_5.bin\n",
    "#********************\n",
    "\n",
    "#********************\n",
    "#*** FINISH tema 4: \n",
    "#*** best recall at 1: 0.7134860050890586 with parameters (0.08, 5, 5)\n",
    "#*** model stored at _model_ptvec_ng2_4_best_at_1.bin\n",
    "#*** best recall at 5: 0.9231552162849873 with dimensions (0.05, 5, 5)\n",
    "#*** model stored at _model_ptvec_ng2_4_best_at_5.bin\n",
    "#********************\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "# number of repetitions\n",
    "N = 3\n",
    "\n",
    "# temas\n",
    "temas = [3,4]\n",
    "\n",
    "word_ngrams = 2\n",
    "# prefix for the generated model\n",
    "model_name = \"_model_ptvec_ng\" + str(word_ngrams) + \"_\"\n",
    "\n",
    "# parameters\n",
    "dim = 300\n",
    "lrs = [0.05, 0.08]\n",
    "window_sizes = [5]\n",
    "epochs = [5,10]\n",
    "#neg_samples = [5,6,7]\n",
    "#word_ngrams = [1,2,3]\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "\n",
    "# create a model for each \"tema\"\n",
    "for t in temas:\n",
    "    tema = str(t)\n",
    "    \n",
    "    best_classifier_at_1 = None\n",
    "    best_parameters_at_1 = None\n",
    "    best_classifier_at_5 = None\n",
    "    best_parameters_at_5 = None \n",
    "    \n",
    "    best_recall_at_1 = 0\n",
    "    best_recall_at_5 = 0\n",
    "\n",
    "    print(\"*** BEGIN tema \" + tema + \": \")\n",
    "    \n",
    "    # Perfomr a grid search for all combinations of parameters. \n",
    "    # For every combination do N repetitions\n",
    "    \n",
    "    dim_ant = 0\n",
    "    for (lr,ws,e) in itertools.product(lrs,window_sizes,epochs):\n",
    "        for i in range(0,N):\n",
    "            if i == 0:\n",
    "                print(\"Checking the combination \" + str((lr,ws,e)))\n",
    "            sys.stdout.write(str(i) + \" \")\n",
    "            classifier = fasttext.supervised(\"_train_\" + tema + \".tmp\",\n",
    "                                             model_name + tema,\n",
    "                                             label_prefix = ftlabel,\n",
    "                                             dim = dim,\n",
    "                                             lr = lr,\n",
    "                                             ws = ws,\n",
    "                                             epoch = e,\n",
    "                                             pretrained_vectors = wVectors,\n",
    "                                             word_ngrams = word_ngrams,\n",
    "                                             bucket = 2000000\n",
    "                                            )\n",
    "            \n",
    "            result_at_1 = classifier.test(\"_dev_\" + tema + \".tmp\", k=1)\n",
    "            result_at_5 = classifier.test(\"_dev_\" + tema + \".tmp\", k=5)\n",
    "\n",
    "            if result_at_1.recall > best_recall_at_1:\n",
    "                best_recall_at_1 = result_at_1.recall\n",
    "                best_classifier_at_1 = classifier\n",
    "                best_parameters_at_1 = (lr,ws,e)\n",
    "                shutil.copyfile(model_name + tema + \".bin\", model_name + tema + \"_best_at_1.bin\")\n",
    "                print(\"* updating best recall at 1 with parameters \" + str(best_parameters_at_1) + \" best recall at 1 so far: \" + str(best_recall_at_1))\n",
    "\n",
    "            if result_at_5.recall > best_recall_at_5:\n",
    "                best_recall_at_5 = result_at_5.recall \n",
    "                best_classifier_at_5 = classifier\n",
    "                best_parameters_at_5 = (lr,ws,e)\n",
    "                shutil.copyfile(model_name + tema + \".bin\", model_name + tema + \"_best_at_5.bin\")\n",
    "                print(\"* updating best recall at 5 with parameters \" + str(best_parameters_at_5) + \" best recall at 5 so far: \" + str(best_recall_at_5))\n",
    "\n",
    "            os.remove(model_name + tema + \".bin\")\n",
    "            if i == N-1:\n",
    "                print(\" (done)\")\n",
    "\n",
    "    print(\"********************\")\n",
    "    print(\"*** FINISH tema \" + tema + \": \")\n",
    "    print(\"*** best recall at 1: \" + str(best_recall_at_1) + \" with parameters \" + str(best_parameters_at_1))\n",
    "    print(\"*** model stored at \" + model_name + tema + \"_best_at_1.bin\")\n",
    "    print(\"*** best recall at 5: \" + str(best_recall_at_5) + \" with dimensions \" + str(best_parameters_at_5))\n",
    "    print(\"*** model stored at \" + model_name + tema + \"_best_at_5.bin\")\n",
    "    print(\"********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
