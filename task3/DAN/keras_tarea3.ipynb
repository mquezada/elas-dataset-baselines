{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from itertools import product\n",
    "import unicodedata\n",
    "import re\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from keras.models import load_model, Model\n",
    "from keras.layers import Dense, Dropout, Input, Embedding, Lambda\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = {}\n",
    "for column in ['x', 'y']:\n",
    "    dict_set = {}\n",
    "    for set_ in ['train', 'dev', 'test']:\n",
    "        filename = '../../data/tarea3/'+column+'_'+set_+'_modo.txt'\n",
    "        with open(filename) as f:\n",
    "            data = f.readlines()\n",
    "        dict_set[set_] = [row[:-1] for row in data]\n",
    "    df[column] = dict_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Que se respete el espíritu de la ley y esta no se pueda interpretar de forma fraudulenta o malintencionada. Implica leyes bien redactadas.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x']['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors and Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import FastText\n",
    "model = FastText.load_word2vec_format('../../word_vectors/ca-vectors.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "vocab_size = len(model.vocab)\n",
    "embedding_matrix = np.zeros((vocab_size+1, EMBEDDING_DIM))\n",
    "for word in model.vocab:\n",
    "    index = model.vocab[word].index\n",
    "    embedding_matrix[index+1, :] = model[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global encoder       # to detect number of classes\n",
    "def get_y_sets():\n",
    "    TRAIN_SIZE = len(df['x']['train'])\n",
    "    DEV_SIZE = len(df['x']['dev'])\n",
    "    TEST_SIZE = len(df['x']['test'])\n",
    "    df_y = np.array(df['y']['train'] + df['y']['dev'] + df['y']['test'])\n",
    "    # one hot vector label for clasification\n",
    "    global encoder\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(df_y) # to know how many classes \n",
    "    labels = encoder.transform(df_y)\n",
    "    Y = to_categorical(np.asarray(labels))\n",
    "    \n",
    "    y_train = Y[0 : TRAIN_SIZE]\n",
    "    y_dev = Y[TRAIN_SIZE : TRAIN_SIZE+DEV_SIZE]\n",
    "    y_test = Y[TRAIN_SIZE+DEV_SIZE : ]\n",
    "    return y_train, y_dev, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global df_x, sequences, MAX_SEQUENCE_LENGTH\n",
    "df_x = [None, None, None, None]              # argumentos de train+dev+test para cada tema\n",
    "sequences = []                               # argumentos como listas de palabras para cada tema\n",
    "MAX_SEQUENCE_LENGTH = 0                      # tamaño máximo de vector de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_x():\n",
    "    '''\n",
    "    Converts arguments in word sequence saving it in global sequences array \n",
    "    Updates the global max sequence length.\n",
    "    \n",
    "    Arguments:\n",
    "        num_df: theme number to process\n",
    "    '''\n",
    "    global MAX_SEQUENCE_LENGTH, df_x, sequences\n",
    "    df_x = np.array(df['x']['train'] + df['x']['dev'] + df['x']['test'])\n",
    "    # to list of words\n",
    "    sequences = []\n",
    "    for argument_j in range(0, df_x.shape[0]):\n",
    "        in_string = df_x[argument_j]\n",
    "        sequences.append(text_to_word_sequence(in_string))\n",
    "    # search for the biggest\n",
    "    for sequence in sequences:\n",
    "        if len(sequence) > MAX_SEQUENCE_LENGTH:\n",
    "            MAX_SEQUENCE_LENGTH = len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x_sets():\n",
    "    '''\n",
    "    Replaces word in sequences for corresponding numbers.\n",
    "    Arguments:\n",
    "        num_df: theme number from which to get the sets\n",
    "    Returns:\n",
    "        Train, development and test set\n",
    "    '''\n",
    "    global df_x, sequences\n",
    "    # every X[i] with max size\n",
    "    # replace words by numbers with world_dict\n",
    "    index2word_set = set(model.index2word)\n",
    "    X = np.zeros((df_x.shape[0], MAX_SEQUENCE_LENGTH)).astype(int)\n",
    "    for i in range(0, len(sequences)):\n",
    "        for j in range(0, len(sequences[i])):\n",
    "            word = sequences[i][j]\n",
    "            if word in index2word_set: \n",
    "                X[i][-len(sequences[i])+j] = model.vocab[word].index+1\n",
    "            else:\n",
    "                X[i][-len(sequences[i])+j] = 0\n",
    "    # divide sets for answer\n",
    "    TRAIN_SIZE = len(df['x']['train'])\n",
    "    DEV_SIZE = len(df['x']['dev'])\n",
    "    TEST_SIZE = len(df['x']['test'])\n",
    "    X_train = X[0 : TRAIN_SIZE]\n",
    "    X_dev = X[TRAIN_SIZE : TRAIN_SIZE+DEV_SIZE]\n",
    "    X_test = X[TRAIN_SIZE+DEV_SIZE : ]\n",
    "    return X_train, X_dev, X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess_x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['que', 'se', 'respete', 'el', 'espíritu', 'de', 'la', 'ley', 'y', 'esta', 'no', 'se', 'pueda', 'interpretar', 'de', 'forma', 'fraudulenta', 'o', 'malintencionada', 'implica', 'leyes', 'bien', 'redactadas']\n",
      "espíritu\n"
     ]
    }
   ],
   "source": [
    "print(sequences[0])\n",
    "print(sequences[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "[ 0.  1.  0.] [ 1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "y_train, y_dev, y_test = get_y_sets()\n",
    "print(df['y']['train'][0], df['y']['train'][10])\n",
    "print(y_train[0], y_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train best configuration models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 macro\n",
    "Metric no longer available in Keras  \n",
    "Functions taken from old code\n",
    "A callback was created to calculate it and save checkpoint accord to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "from sklearn import metrics\n",
    "\n",
    "class ModelCheckpointF1Macro(Callback):\n",
    "    '''Sets f1-macro as monitor, and calculates the metric with scikit functions'''\n",
    "    def __init__(self, filepath, monitor='f1-macro', verbose=0, \n",
    "                 save_best_only=False, save_weights_only=False):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.filepath = filepath\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.best = -np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if self.save_best_only:\n",
    "            # this part was added\n",
    "            scores_pred = self.model.predict(X_dev, batch_size=30) # get scores for each class\n",
    "            index_pred = np.argmax(scores_pred, axis=1) # get index qith max score\n",
    "            y_true = np.argmax(y_dev, axis=1)\n",
    "            current = metrics.f1_score(y_true, index_pred, average='macro')\n",
    "            # --\n",
    "            if current is None:\n",
    "                warnings.warn(\"Can save best model only with %s available, skipping.\" % (self.monitor), RuntimeWarning)\n",
    "            else:\n",
    "                if current > self.best:\n",
    "                    if self.verbose > 0:\n",
    "                        print(\"Epoch %05d: %s improved from %0.5f to %0.5f, saving model to %s\"\n",
    "                            % (epoch, self.monitor, self.best, current, self.filepath))\n",
    "                    self.best = current\n",
    "                    if self.save_weights_only:\n",
    "                        self.model.save_weights(self.filepath, overwrite=True)\n",
    "                    else:\n",
    "                        self.model.save(self.filepath, overwrite=True)\n",
    "                else:\n",
    "                    if self.verbose > 0:\n",
    "                        print(\"Epoch %05d: %s did not improve\" % (epoch, self.monitor))\n",
    "        else:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: saving model to %s\" % (epoch, self.filepath))\n",
    "            self.model.save_weights(self.filepath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dan(relu_layers=3, hidden_units=300, p_dropout=0.3, dropout_input=False, \n",
    "        my_regularizer=regularizers.l2(1e-5), my_optimizer='adam', \n",
    "        epochs=150, batch_size=200, trainable=False, filepath=''):\n",
    "    '''\n",
    "    Creates and fit NN. \n",
    "    NN Arquitecture: \n",
    "        Input: vector with numbers representing index in embedding layer\n",
    "        Embedding layer: matrix multiplication to obtain vectors for each index in the input\n",
    "        Dropout: optional words dropout\n",
    "        Mean: Averages the vectors of the embedding output, returning one averaged vector\n",
    "        Fully connected: Fully connected layers with relu as activation function\n",
    "                         optional neuron dropout\n",
    "        Fully connected: output layer with softmax function\n",
    "    \n",
    "    Arguments:\n",
    "        relu_layers: Number of fully connected layers with relu \n",
    "        hidden_units: Number of neurons on the relu layers\n",
    "        p_dropout: dropout probability for the relu layers\n",
    "        dropout_input: dropout probability for words \n",
    "        my_regularizer: kernel_regularizer for fully connected layers\n",
    "        my_optimizer: optimizer for back propagation\n",
    "        epochs: number of epochs to train\n",
    "        batch_size: batch_size for trainning\n",
    "    '''\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int64')\n",
    "    x = Embedding(len(model.vocab)+ 1, EMBEDDING_DIM, mask_zero=True,\n",
    "                  weights=[embedding_matrix], trainable=trainable)(sequence_input)\n",
    "    if dropout_input:\n",
    "        x = Dropout(0.2)(x)\n",
    "    x = Lambda(lambda x: K.mean(x, axis=1), \n",
    "               output_shape=(embedding_matrix.shape[1],))(x)\n",
    "    for i in range(0, relu_layers):\n",
    "        x = Dropout(p_dropout)(x)\n",
    "        x = Dense(units=hidden_units, activation='relu', kernel_regularizer=my_regularizer)(x)\n",
    "    preds = Dense(units=len(encoder.classes_), activation='softmax', \n",
    "                  kernel_regularizer=my_regularizer)(x)\n",
    "    \n",
    "    m = Model(sequence_input, preds)\n",
    "    m.compile(loss='categorical_crossentropy', optimizer=my_optimizer, \n",
    "              metrics=['accuracy'])\n",
    "    print (\"Starting trainning\")\n",
    "    \n",
    "    checkpoint = ModelCheckpointF1Macro(filepath, verbose=1, save_best_only=True)\n",
    "    callbacks_list = [checkpoint]\n",
    "    m.fit(X_train, y_train,\n",
    "          validation_data=(X_dev, y_dev),\n",
    "          shuffle=True, \n",
    "          epochs=epochs, batch_size=batch_size,\n",
    "          verbose=0,\n",
    "          callbacks=callbacks_list)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_hyperparam = [(2, 200, None, 0.2, 30, 130)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_dev, y_test = get_y_sets()\n",
    "X_train, X_dev, X_test = get_x_sets()\n",
    "best = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Checking combination: (2, 200, None, 0.2)\n",
      "Starting trainning\n",
      "Epoch 00000: f1-macro improved from -inf to 0.49888, saving model to models/checkpoint.h5\n",
      "Epoch 00001: f1-macro improved from 0.49888 to 0.51435, saving model to models/checkpoint.h5\n",
      "Epoch 00002: f1-macro improved from 0.51435 to 0.55985, saving model to models/checkpoint.h5\n",
      "Epoch 00003: f1-macro did not improve\n",
      "Epoch 00004: f1-macro improved from 0.55985 to 0.56404, saving model to models/checkpoint.h5\n",
      "Epoch 00005: f1-macro improved from 0.56404 to 0.59040, saving model to models/checkpoint.h5\n",
      "Epoch 00006: f1-macro did not improve\n",
      "Epoch 00007: f1-macro did not improve\n",
      "Epoch 00008: f1-macro did not improve\n",
      "Epoch 00009: f1-macro improved from 0.59040 to 0.59316, saving model to models/checkpoint.h5\n",
      "Epoch 00010: f1-macro did not improve\n",
      "Epoch 00011: f1-macro did not improve\n",
      "Epoch 00012: f1-macro improved from 0.59316 to 0.59741, saving model to models/checkpoint.h5\n",
      "Epoch 00013: f1-macro did not improve\n",
      "Epoch 00014: f1-macro did not improve\n",
      "Epoch 00015: f1-macro did not improve\n",
      "Epoch 00016: f1-macro did not improve\n",
      "Epoch 00017: f1-macro did not improve\n",
      "Epoch 00018: f1-macro did not improve\n",
      "Epoch 00019: f1-macro did not improve\n",
      "Epoch 00020: f1-macro improved from 0.59741 to 0.60148, saving model to models/checkpoint.h5\n",
      "Epoch 00021: f1-macro did not improve\n",
      "Epoch 00022: f1-macro did not improve\n",
      "Epoch 00023: f1-macro did not improve\n",
      "Epoch 00024: f1-macro did not improve\n",
      "Epoch 00025: f1-macro did not improve\n",
      "Epoch 00026: f1-macro did not improve\n",
      "Epoch 00027: f1-macro did not improve\n",
      "Epoch 00028: f1-macro did not improve\n",
      "Epoch 00029: f1-macro did not improve\n",
      "Epoch 00030: f1-macro did not improve\n",
      "Epoch 00031: f1-macro did not improve\n",
      "Epoch 00032: f1-macro did not improve\n",
      "Epoch 00033: f1-macro improved from 0.60148 to 0.60536, saving model to models/checkpoint.h5\n",
      "Epoch 00034: f1-macro improved from 0.60536 to 0.60557, saving model to models/checkpoint.h5\n",
      "Epoch 00035: f1-macro improved from 0.60557 to 0.60826, saving model to models/checkpoint.h5\n",
      "Epoch 00036: f1-macro did not improve\n",
      "Epoch 00037: f1-macro did not improve\n",
      "Epoch 00038: f1-macro did not improve\n",
      "Epoch 00039: f1-macro did not improve\n",
      "Epoch 00040: f1-macro did not improve\n",
      "Epoch 00041: f1-macro did not improve\n",
      "Epoch 00042: f1-macro did not improve\n",
      "Epoch 00043: f1-macro did not improve\n",
      "Epoch 00044: f1-macro did not improve\n",
      "Epoch 00045: f1-macro did not improve\n",
      "Epoch 00046: f1-macro did not improve\n",
      "Epoch 00047: f1-macro did not improve\n",
      "Epoch 00048: f1-macro did not improve\n",
      "Epoch 00049: f1-macro did not improve\n",
      "Epoch 00050: f1-macro did not improve\n",
      "Epoch 00051: f1-macro did not improve\n",
      "Epoch 00052: f1-macro did not improve\n",
      "Epoch 00053: f1-macro did not improve\n",
      "Epoch 00054: f1-macro improved from 0.60826 to 0.61424, saving model to models/checkpoint.h5\n",
      "Epoch 00055: f1-macro did not improve\n",
      "Epoch 00056: f1-macro did not improve\n",
      "Epoch 00057: f1-macro did not improve\n",
      "Epoch 00058: f1-macro did not improve\n",
      "Epoch 00059: f1-macro did not improve\n",
      "Epoch 00060: f1-macro did not improve\n",
      "Epoch 00061: f1-macro did not improve\n",
      "Epoch 00062: f1-macro did not improve\n",
      "Epoch 00063: f1-macro did not improve\n",
      "Epoch 00064: f1-macro did not improve\n",
      "Epoch 00065: f1-macro did not improve\n",
      "Epoch 00066: f1-macro did not improve\n",
      "Epoch 00067: f1-macro did not improve\n",
      "Epoch 00068: f1-macro did not improve\n",
      "Epoch 00069: f1-macro did not improve\n",
      "Epoch 00070: f1-macro did not improve\n",
      "Epoch 00071: f1-macro did not improve\n",
      "Epoch 00072: f1-macro did not improve\n",
      "Epoch 00073: f1-macro did not improve\n",
      "Epoch 00074: f1-macro did not improve\n",
      "Epoch 00075: f1-macro did not improve\n",
      "Epoch 00076: f1-macro did not improve\n",
      "Epoch 00077: f1-macro did not improve\n",
      "Epoch 00078: f1-macro improved from 0.61424 to 0.62143, saving model to models/checkpoint.h5\n",
      "Epoch 00079: f1-macro did not improve\n",
      "Epoch 00080: f1-macro did not improve\n",
      "Epoch 00081: f1-macro did not improve\n",
      "Epoch 00082: f1-macro did not improve\n",
      "Epoch 00083: f1-macro did not improve\n",
      "Epoch 00084: f1-macro did not improve\n",
      "Epoch 00085: f1-macro did not improve\n",
      "Epoch 00086: f1-macro did not improve\n",
      "Epoch 00087: f1-macro did not improve\n",
      "Epoch 00088: f1-macro did not improve\n",
      "Epoch 00089: f1-macro did not improve\n",
      "Epoch 00090: f1-macro did not improve\n",
      "Epoch 00091: f1-macro did not improve\n",
      "Epoch 00092: f1-macro did not improve\n",
      "Epoch 00093: f1-macro did not improve\n",
      "Epoch 00094: f1-macro did not improve\n",
      "Epoch 00095: f1-macro did not improve\n",
      "Epoch 00096: f1-macro did not improve\n",
      "Epoch 00097: f1-macro did not improve\n",
      "Epoch 00098: f1-macro did not improve\n",
      "Epoch 00099: f1-macro did not improve\n",
      "Epoch 00100: f1-macro did not improve\n",
      "Epoch 00101: f1-macro did not improve\n",
      "Epoch 00102: f1-macro did not improve\n",
      "Epoch 00103: f1-macro did not improve\n",
      "Epoch 00104: f1-macro did not improve\n",
      "Epoch 00105: f1-macro did not improve\n",
      "Epoch 00106: f1-macro did not improve\n",
      "Epoch 00107: f1-macro did not improve\n",
      "Epoch 00108: f1-macro did not improve\n",
      "Epoch 00109: f1-macro did not improve\n",
      "Epoch 00110: f1-macro did not improve\n",
      "Epoch 00111: f1-macro did not improve\n",
      "Epoch 00112: f1-macro did not improve\n",
      "Epoch 00113: f1-macro did not improve\n",
      "Epoch 00114: f1-macro did not improve\n",
      "Epoch 00115: f1-macro did not improve\n",
      "Epoch 00116: f1-macro did not improve\n",
      "Epoch 00117: f1-macro did not improve\n",
      "Epoch 00118: f1-macro did not improve\n",
      "Epoch 00119: f1-macro did not improve\n",
      "f1-macro dev: 0.621428862526\n",
      "UPDATING BEST MODEL 0.621428862526\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "for relu_layers, hidden_units, l2, dropout, batch_size, epochs in final_hyperparam:\n",
    "    print(\">>Checking combination: \"+str((relu_layers, hidden_units, l2, dropout)))\n",
    "    m = dan(relu_layers=relu_layers, hidden_units=hidden_units, \n",
    "            p_dropout=dropout, my_regularizer=l2,\n",
    "            epochs=120, batch_size=batch_size,\n",
    "            filepath='models/checkpoint.h5')\n",
    "    \n",
    "    m = load_model('models/checkpoint.h5')\n",
    "    scores_pred = m.predict(X_dev, batch_size=batch_size) # get scores for each class\n",
    "    index_pred = np.argmax(scores_pred, axis=1) # get index qith max score\n",
    "    y_true = np.argmax(y_dev, axis=1)\n",
    "    val = metrics.f1_score(y_true, index_pred, average='macro')\n",
    "    print('f1-macro dev: '+str(val))\n",
    "    if val > best:\n",
    "        print(\"UPDATING BEST MODEL \"+str(val))\n",
    "        best = val\n",
    "        m.save('models/best.h5')\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  67.4\n",
      "Recall:  58.6\n",
      "F1:  61.9\n"
     ]
    }
   ],
   "source": [
    "m_check = load_model('models/checkpoint.h5')\n",
    "scores = m_check.predict(X_test, batch_size=30)\n",
    "y_pred = np.argmax(scores, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "# precision recall f1\n",
    "print(\"Precision: \", round(100*metrics.precision_score(y_true, y_pred, average='macro'), 1))\n",
    "print(\"Recall: \", round(100*metrics.recall_score(y_true, y_pred, average='macro'), 1))\n",
    "print(\"F1: \", round(100*metrics.f1_score(y_true, y_pred, average='macro') , 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow python 3",
   "language": "python",
   "name": "tensorflow-p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
